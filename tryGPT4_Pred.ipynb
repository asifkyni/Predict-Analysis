{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64faccae-06e8-4616-8959-9ccfc646d87e",
   "metadata": {},
   "source": [
    "Using GPT-4 for forecasting tasks is a bit different from traditional time series forecasting methods, as GPT-4 is primarily designed for text generation and understanding. However, it can be applied to tasks like text-based forecasting or generating future sequences based on past data.\n",
    "\n",
    "### Approach to Using GPT-4 for Forecasting\n",
    "\n",
    "1. **Set Up the Environment**: Ensure you have access to GPT-4 via OpenAI's API or similar.\n",
    "2. **Prepare the Data**: Format your historical data as prompts for the model.\n",
    "3. **Make Forecasting Predictions**: Use GPT-4 to generate future values based on the prompts.\n",
    "4. **Evaluate the Results**: Assess the predictions against actual values.\n",
    "\n",
    "### 1. Set Up the Environment\n",
    "\n",
    "To use GPT-4, you need to set up the OpenAI API. You can install the required library if you haven't already:\n",
    "\n",
    "```bash\n",
    "pip install openai\n",
    "```\n",
    "\n",
    "### 2. Prepare the Data\n",
    "\n",
    "Assuming we want to use the Air Passenger dataset for this example, format the data into a prompt.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Air Passenger dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "df = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "\n",
    "# Prepare the last few months of data as a prompt\n",
    "last_data = df[-12:]  # Get the last 12 months of data\n",
    "prompt = \"Here are the last 12 months of airline passenger data:\\n\" + \\\n",
    "         \"\\n\".join(f\"{index.date()}: {row[0]}\" for index, row in last_data.iterrows()) + \\\n",
    "         \"\\nPredict the next 12 months of passenger data.\"\n",
    "```\n",
    "\n",
    "### 3. Make Forecasting Predictions\n",
    "\n",
    "Now we can call GPT-4 to generate the forecast based on the prompt.\n",
    "\n",
    "```python\n",
    "import openai\n",
    "\n",
    "# Initialize the OpenAI API (replace 'your-api-key' with your actual API key)\n",
    "openai.api_key = 'your-api-key'\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Extract the generated text\n",
    "forecast = response['choices'][0]['message']['content']\n",
    "print(\"Forecasted Data:\\n\", forecast)\n",
    "```\n",
    "\n",
    "### 4. Evaluate the Results\n",
    "\n",
    "Since GPT-4 generates text, you'll need to extract and parse the forecasted values from the output.\n",
    "\n",
    "```python\n",
    "# Convert the forecasted output into a usable format\n",
    "# For simplicity, assume the forecast is outputted in the same format as input\n",
    "# You might need to write additional parsing logic based on actual output format\n",
    "\n",
    "# For demonstration, let's assume the forecast format is straightforward:\n",
    "forecasted_values = [line.split(\": \")[1] for line in forecast.split(\"\\n\") if \":\" in line]\n",
    "forecasted_values = [float(value) for value in forecasted_values]\n",
    "\n",
    "# Plot the actual vs. predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=12, freq='M')\n",
    "forecast_df = pd.DataFrame(forecasted_values, index=future_dates, columns=['Forecasted Passengers'])\n",
    "\n",
    "# Combine actual and forecast data for visualization\n",
    "combined_df = pd.concat([df, forecast_df])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(combined_df.index, combined_df['Passengers'], label='Actual Passengers', marker='o')\n",
    "plt.plot(forecast_df.index, forecast_df['Forecasted Passengers'], label='Forecasted Passengers', marker='o', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Airline Passengers Forecasting using GPT-4')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "Using GPT-4 for forecasting involves formatting historical data into a prompt and generating predictions in natural language. It can be an interesting approach, especially for generating narrative-based forecasts or insights. However, keep in mind that for quantitative forecasting, traditional time series models (like ARIMA, LSTM, etc.) might yield more accurate and reliable results.\n",
    "\n",
    "If you have specific requirements or want to explore a different dataset, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61086073-83ae-4e23-96d0-5000aa612d58",
   "metadata": {},
   "source": [
    "### 1. Set Up the Environment\n",
    "* To use GPT-4, you need to set up the OpenAI API. You can install the required library if you haven't already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecdac1a1-986f-461e-9173-53347d818446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.47.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (2.7.4)\n",
      "Requirement already satisfied: sniffio in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Downloading openai-1.47.1-py3-none-any.whl (375 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.5.0 openai-1.47.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea34802-22d6-4f36-a11b-dd8339b70825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (1.47.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (2.7.4)\n",
      "Requirement already satisfied: sniffio in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b7c8b-67ae-4866-b121-01551c0a1fd6",
   "metadata": {},
   "source": [
    "### 2. Prepare the Data\n",
    "* Assuming we want to use the Air Passenger dataset for this example, format the data into a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d17eca-f2dc-409d-bce3-58cf3b604d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Air Passenger dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "df = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "\n",
    "# Prepare the last few months of data as a prompt\n",
    "last_data = df[-12:]  # Get the last 12 months of data\n",
    "prompt = \"Here are the last 12 months of airline passenger data:\\n\" + \\\n",
    "         \"\\n\".join(f\"{index.date()}: {row[0]}\" for index, row in last_data.iterrows()) + \\\n",
    "         \"\\nPredict the next 12 months of passenger data.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d310a2f-5c7e-4478-a503-9df9434a9b4f",
   "metadata": {},
   "source": [
    "### 3. Make Forecasting Predictions\n",
    "* Now we can call GPT-4 to generate the forecast based on the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d273c7ad-c51b-418b-a2bd-d9659dcb9666",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the OpenAI API (replace 'your-api-key' with your actual API key)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour-api-key\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Extract the generated text\u001b[39;00m\n\u001b[1;32m     14\u001b[0m forecast \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI API (replace 'your-api-key' with your actual API key)\n",
    "openai.api_key = 'your-api-key'\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Extract the generated text\n",
    "forecast = response['choices'][0]['message']['content']\n",
    "print(\"Forecasted Data:\\n\", forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d05918-2dc0-4c54-9165-7015f708e54c",
   "metadata": {},
   "source": [
    "### 4. Evaluate the Results\n",
    "* Since GPT-4 generates text, you'll need to extract and parse the forecasted values from the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441d22b8-ba3f-4bcc-9ffd-0e797596aa2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forecast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the forecasted output into a usable format\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# For simplicity, assume the forecast is outputted in the same format as input\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# You might need to write additional parsing logic based on actual output format\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# For demonstration, let's assume the forecast format is straightforward:\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m forecasted_values \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mforecast\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line]\n\u001b[1;32m      7\u001b[0m forecasted_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(value) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m forecasted_values]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Plot the actual vs. predicted values\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forecast' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert the forecasted output into a usable format\n",
    "# For simplicity, assume the forecast is outputted in the same format as input\n",
    "# You might need to write additional parsing logic based on actual output format\n",
    "\n",
    "# For demonstration, let's assume the forecast format is straightforward:\n",
    "forecasted_values = [line.split(\": \")[1] for line in forecast.split(\"\\n\") if \":\" in line]\n",
    "forecasted_values = [float(value) for value in forecasted_values]\n",
    "\n",
    "# Plot the actual vs. predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=12, freq='M')\n",
    "forecast_df = pd.DataFrame(forecasted_values, index=future_dates, columns=['Forecasted Passengers'])\n",
    "\n",
    "# Combine actual and forecast data for visualization\n",
    "combined_df = pd.concat([df, forecast_df])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(combined_df.index, combined_df['Passengers'], label='Actual Passengers', marker='o')\n",
    "plt.plot(forecast_df.index, forecast_df['Forecasted Passengers'], label='Forecasted Passengers', marker='o', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Airline Passengers Forecasting using GPT-4')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ff45de-c4ef-4322-9367-027df0018da3",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour-api-key\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create a completion request\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or \"gpt-4\" if available\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limit the response length\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Extract the generated text\u001b[39;00m\n\u001b[1;32m     28\u001b[0m forecast \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "# Load the Air Passenger dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "df = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "\n",
    "# Prepare the last few months of data as a prompt\n",
    "last_data = df[-12:]  # Get the last 12 months of data\n",
    "prompt = \"Here are the last 12 months of airline passenger data:\\n\" + \\\n",
    "         \"\\n\".join(f\"{index.date()}: {row[0]}\" for index, row in last_data.iterrows()) + \\\n",
    "         \"\\nPredict the next 12 months of passenger data.\"\n",
    "\n",
    "# Initialize the OpenAI API (replace 'your-api-key' with your actual API key)\n",
    "openai.api_key = 'your-api-key'\n",
    "\n",
    "# Create a completion request\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",  # or \"gpt-4\" if available\n",
    "    prompt=prompt,\n",
    "    max_tokens=100,  # Limit the response length\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "# Extract the generated text\n",
    "forecast = response['choices'][0]['text'].strip()\n",
    "print(\"Forecasted Data:\\n\", forecast)\n",
    "\n",
    "# Convert the forecasted output into a usable format\n",
    "# Assuming the forecast follows a simple format of one value per line\n",
    "forecasted_values = [line.split(\": \")[1] for line in forecast.split(\"\\n\") if \":\" in line]\n",
    "forecasted_values = [float(value) for value in forecasted_values]\n",
    "\n",
    "# Plot the actual vs. predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=12, freq='M')\n",
    "forecast_df = pd.DataFrame(forecasted_values, index=future_dates, columns=['Forecasted Passengers'])\n",
    "\n",
    "# Combine actual and forecast data for visualization\n",
    "combined_df = pd.concat([df, forecast_df])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(combined_df.index, combined_df['Passengers'], label='Actual Passengers', marker='o')\n",
    "plt.plot(forecast_df.index, forecast_df['Forecasted Passengers'], label='Forecasted Passengers', marker='o', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Airline Passengers Forecasting using GPT-4')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45db56f8-6967-4917-9c8f-732098b73a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour-api-key\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create a chat completion request\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limit the response length\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Extract the generated text\u001b[39;00m\n\u001b[1;32m     28\u001b[0m forecast \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "# Load the Air Passenger dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "df = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "\n",
    "# Prepare the last few months of data as a prompt\n",
    "last_data = df[-12:]  # Get the last 12 months of data\n",
    "prompt = \"Here are the last 12 months of airline passenger data:\\n\" + \\\n",
    "         \"\\n\".join(f\"{index.date()}: {row[0]}\" for index, row in last_data.iterrows()) + \\\n",
    "         \"\\nPredict the next 12 months of passenger data.\"\n",
    "\n",
    "# Initialize the OpenAI API (replace 'your-api-key' with your actual API key)\n",
    "openai.api_key = 'your-api-key'\n",
    "\n",
    "# Create a chat completion request\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=100,  # Limit the response length\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "# Extract the generated text\n",
    "forecast = response['choices'][0]['message']['content'].strip()\n",
    "print(\"Forecasted Data:\\n\", forecast)\n",
    "\n",
    "# Convert the forecasted output into a usable format\n",
    "# Assuming the forecast follows a simple format of one value per line\n",
    "forecasted_values = [line.split(\": \")[1] for line in forecast.split(\"\\n\") if \":\" in line]\n",
    "forecasted_values = [float(value) for value in forecasted_values]\n",
    "\n",
    "# Plot the actual vs. predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=12, freq='M')\n",
    "forecast_df = pd.DataFrame(forecasted_values, index=future_dates, columns=['Forecasted Passengers'])\n",
    "\n",
    "# Combine actual and forecast data for visualization\n",
    "combined_df = pd.concat([df, forecast_df])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(combined_df.index, combined_df['Passengers'], label='Actual Passengers', marker='o')\n",
    "plt.plot(forecast_df.index, forecast_df['Forecasted Passengers'], label='Forecasted Passengers', marker='o', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Airline Passengers Forecasting using GPT-4')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6c0dcf-ff3b-428d-bd81-e35c3415f0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (1.47.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (2.7.4)\n",
      "Requirement already satisfied: sniffio in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n"
     ]
    }
   ],
   "source": [
    "# install from PyPI\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccad178-457c-4d3b-b898-014543451b38",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 4\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# This is the default and can be omitted\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     10\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     11\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d46da-655a-4e0c-8eb4-b12f8a9c741f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
